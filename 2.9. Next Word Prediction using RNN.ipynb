{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b06f8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "87c722ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data='''Python is a high level general purpose programming language Its design philosophy emphasizes code readability with the\n",
    "use of significant indentation Python is dynamically typed and garbage collected It supports multiple programming paradigms\n",
    "including structured object oriented and functional programming'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aff6bb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 2,\n",
       " 3,\n",
       " 23,\n",
       " 24,\n",
       " 4,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 1,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 4,\n",
       " 35,\n",
       " 1]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded_data=tokenizer.texts_to_sequences([data])[0]\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b95bab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "be79ce32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 36\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size : %d\" % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "494341ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3],\n",
       " [3, 5],\n",
       " [5, 6],\n",
       " [6, 7],\n",
       " [7, 8],\n",
       " [8, 9],\n",
       " [9, 1],\n",
       " [1, 10],\n",
       " [10, 11],\n",
       " [11, 12],\n",
       " [12, 13],\n",
       " [13, 14],\n",
       " [14, 15],\n",
       " [15, 16],\n",
       " [16, 17],\n",
       " [17, 18],\n",
       " [18, 19],\n",
       " [19, 20],\n",
       " [20, 21],\n",
       " [21, 22],\n",
       " [22, 2],\n",
       " [2, 3],\n",
       " [3, 23],\n",
       " [23, 24],\n",
       " [24, 4],\n",
       " [4, 25],\n",
       " [25, 26],\n",
       " [26, 27],\n",
       " [27, 28],\n",
       " [28, 29],\n",
       " [29, 1],\n",
       " [1, 30],\n",
       " [30, 31],\n",
       " [31, 32],\n",
       " [32, 33],\n",
       " [33, 34],\n",
       " [34, 4],\n",
       " [4, 35],\n",
       " [35, 1]]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences=list()\n",
    "for i in range(1,len(encoded_data)):\n",
    "    sequence=encoded_data[i-1:i+1]\n",
    "    sequences.append(sequence)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "46087b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences : 39\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Sequences : %d\" % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "cba9d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences=array(sequences)\n",
    "X,Y=sequences[:,0],sequences[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ca5a1727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 5, 6, 7])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b8cd9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=to_categorical(Y,num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e30b300a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "05dbcae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 1, 10)             360       \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 50)                12200     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 36)                1836      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,396\n",
      "Trainable params: 14,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,10,input_length=1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size,activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5b4a7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=(['accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1fcba46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 5s 12ms/step - loss: 3.5831 - accuracy: 0.0256\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.5821 - accuracy: 0.0769\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5813 - accuracy: 0.1026\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5805 - accuracy: 0.1026\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5798 - accuracy: 0.1026\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.5791 - accuracy: 0.1026\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5784 - accuracy: 0.1026\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5777 - accuracy: 0.1026\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.5769 - accuracy: 0.0769\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5762 - accuracy: 0.0769\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5755 - accuracy: 0.0769\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5747 - accuracy: 0.0769\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5740 - accuracy: 0.0769\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5731 - accuracy: 0.0769\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5724 - accuracy: 0.0769\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5715 - accuracy: 0.0769\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5706 - accuracy: 0.0769\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5696 - accuracy: 0.0769\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5686 - accuracy: 0.0769\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5676 - accuracy: 0.0769\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5665 - accuracy: 0.0769\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5655 - accuracy: 0.0769\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5643 - accuracy: 0.0769\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5630 - accuracy: 0.0769\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.5618 - accuracy: 0.0769\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.5604 - accuracy: 0.0769\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5590 - accuracy: 0.0769\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5576 - accuracy: 0.0769\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5560 - accuracy: 0.1282\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5545 - accuracy: 0.1282\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5528 - accuracy: 0.1282\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5510 - accuracy: 0.1282\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5492 - accuracy: 0.1282\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.5474 - accuracy: 0.1282\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5453 - accuracy: 0.1282\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5433 - accuracy: 0.1282\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.5411 - accuracy: 0.1282\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.5388 - accuracy: 0.1282\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5365 - accuracy: 0.1282\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5339 - accuracy: 0.1282\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.5314 - accuracy: 0.1282\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.5286 - accuracy: 0.1282\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.5257 - accuracy: 0.1282\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5226 - accuracy: 0.1282\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.5194 - accuracy: 0.1282\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.5162 - accuracy: 0.1282\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5126 - accuracy: 0.1282\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 3.5090 - accuracy: 0.1282\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.5052 - accuracy: 0.1282\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.5013 - accuracy: 0.1282\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.4973 - accuracy: 0.1282\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.4930 - accuracy: 0.1282\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.4887 - accuracy: 0.1282\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.4841 - accuracy: 0.1282\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.4791 - accuracy: 0.1282\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.4740 - accuracy: 0.1282\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4685 - accuracy: 0.1538\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.4628 - accuracy: 0.1538\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.4568 - accuracy: 0.1795\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 3.4505 - accuracy: 0.1795\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.4442 - accuracy: 0.2051\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4373 - accuracy: 0.2051\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.4303 - accuracy: 0.2308\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.4231 - accuracy: 0.2308\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4156 - accuracy: 0.2308\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.4080 - accuracy: 0.2308\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.3996 - accuracy: 0.2308\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.3914 - accuracy: 0.2308\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3826 - accuracy: 0.2308\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.3733 - accuracy: 0.2308\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3639 - accuracy: 0.2564\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3541 - accuracy: 0.2821\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.3440 - accuracy: 0.2821\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3330 - accuracy: 0.2821\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.3225 - accuracy: 0.2821\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.3108 - accuracy: 0.2821\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2995 - accuracy: 0.2821\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2877 - accuracy: 0.2821\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.2755 - accuracy: 0.2821\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2632 - accuracy: 0.3333\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2500 - accuracy: 0.3333\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2375 - accuracy: 0.3333\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.2237 - accuracy: 0.3590\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 3.2096 - accuracy: 0.3590\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.1954 - accuracy: 0.3590\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.1806 - accuracy: 0.3333\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1650 - accuracy: 0.3590\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1496 - accuracy: 0.3590\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1329 - accuracy: 0.3333\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1176 - accuracy: 0.3333\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.1001 - accuracy: 0.3333\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0837 - accuracy: 0.3077\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0661 - accuracy: 0.3077\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0490 - accuracy: 0.3077\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.0310 - accuracy: 0.3077\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0129 - accuracy: 0.3333\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.9947 - accuracy: 0.3333\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.9768 - accuracy: 0.3333\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9583 - accuracy: 0.3590\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.9397 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2295c6dbc40>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d0d2b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model,tokenizer,enter_text,n_pred):\n",
    "    in_text,result=enter_text,enter_text\n",
    "    for _ in range(n_pred):\n",
    "        encoded=tokenizer.texts_to_sequences([in_text])[0]\n",
    "        encoded=array(encoded)\n",
    "        #yhat=model.predict_classes(encoded)\n",
    "        yhat=np.argmax(model.predict(encoded), axis=1)\n",
    "        out_word=''\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index==yhat:\n",
    "                out_word=word\n",
    "                break\n",
    "        in_text,result=out_word,result + ' ' + out_word   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9e958943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002295C677880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002295C677880> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 1s 991ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "python is a indentation is\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model,tokenizer,'python',4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1ecee1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "programming paradigms programming paradigms programming paradigms\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model,tokenizer,'programming',5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b285b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
